{"cells": [{"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import pandas as pd\n", "import keras\n", "from sklearn.preprocessing import MinMaxScaler\n", "from sklearn.model_selection import train_test_split\n", "#%%\n", "# (1) ---- Import data ----\n", "# Load data\n", "data_raw = pd.read_csv('bank_marketing_balanced.csv')  # Source: https://archive.ics.uci.edu/ml/datasets/bank+marketing#"]}, {"cell_type": "markdown", "metadata": {}, "source": ["% get first impression of the data"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print(data_raw.head(5))"]}, {"cell_type": "markdown", "metadata": {}, "source": ["% get detailed impression of the data"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["for c in data_raw.columns:\n", "    print(c)\n", "    print(data_raw.loc[:, c].unique())  # Show unique values per column"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%<br>\n", "(2) ---- Data pre-processing ----"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["data_pp = data_raw.copy()  # make a copy\n", "# Transform categorical to numeric features\n", "categoricals = ['job', 'marital', 'education', 'default', 'housing', 'loan',\n", "                'contact', 'month', 'day_of_week', 'poutcome', 'y']\n", "df_dummies = pd.get_dummies(\n", "    data_pp.loc[:, categoricals], drop_first=True, dtype=int,\n", "    )\n", "print(df_dummies.info())"]}, {"cell_type": "markdown", "metadata": {}, "source": ["% Drop categorical columns"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print(data_pp)\n", "data_pp = data_pp.drop(categoricals, axis=1)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["% Insert dummies representing the categoricals"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["data_pp = pd.concat([data_pp, df_dummies], axis=1)\n", "print(data_pp)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["% Rename y_yes back to y"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["data_pp.rename(columns={'y_yes': 'y'}, inplace=True)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["% Show output"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print(data_raw.tail(5))\n", "print(data_pp.tail(5))"]}, {"cell_type": "markdown", "metadata": {}, "source": ["% What about class imbalance?"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print(data_pp['y'].value_counts())  # show absolute number of observations per value of y\n", "print(sum(data_pp['y'] == 1) / data_pp.shape[0])  # share of observations where y=1"]}, {"cell_type": "markdown", "metadata": {}, "source": ["% Split in x and y"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["x = data_pp.drop('y', axis=1)\n", "y = data_pp.loc[:, 'y']"]}, {"cell_type": "markdown", "metadata": {}, "source": ["% Split in train and test"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.15)\n", "print(x_train.shape, y_train.shape)\n", "print(x_test.shape, y_test.shape)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["% Split in train and valid"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.15)\n", "print(x_train.shape, y_train.shape)\n", "print(x_val.shape, y_val.shape)\n", "# Hint: to get precise split of 70-15-15 (train-test-valid), do test_size=0.15 and then test_size=0.15/0.85"]}, {"cell_type": "markdown", "metadata": {}, "source": ["% Rescale features with minmax scaling<br>\n", "Neural networks perform pretty well on features ranging between 0 and 1"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["minmax = MinMaxScaler()\n", "print(x_train)  # before scaling\n", "x_train = minmax.fit_transform(x_train)\n", "print(x_train)  # after scaling"]}, {"cell_type": "markdown", "metadata": {}, "source": ["% Transform valid. & test data with min & max parameter of training data"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["x_val = minmax.transform(x_val)\n", "x_test = minmax.transform(x_test)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%<br>\n", "(3) ---- Build, train and evaluate ANN ----<br>\n", "Construct the model (define layers, their units and activation functions)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["no_inputs = x_train.shape[1]"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["mynn = keras.Sequential([\n", "    keras.layers.Dense(units=5, activation='relu', input_dim=no_inputs), # Hidden layer with 5 units and activation function relu\n", "    keras.layers.Dense(units=1, activation='sigmoid')  # output layer with one unit\n", "])"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%<br>\n", "Define how the model is trained (defines the process of backward propagation)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["mynn.compile(optimizer='Adam', loss='binary_crossentropy', metrics=['binary_accuracy'])"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print(mynn.summary())"]}, {"cell_type": "markdown", "metadata": {}, "source": ["% Train the model to optimize all weights"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["train_results = mynn.fit(x=x_train, y=y_train, batch_size=32, epochs=5, \n", "                         validation_data=(x_val, y_val), shuffle=True)\n", "print(train_results.history)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%<br>\n", "Evaluate the performance of the model on (unseen) test data"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["test_results = mynn.evaluate(x=x_test, y=y_test)\n", "print(test_results)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["% Delete model and experiment with different setups"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["del mynn"]}, {"cell_type": "markdown", "metadata": {}, "source": ["% TODO: HYPERPARAMETER OPTIMIZATION"]}, {"cell_type": "markdown", "metadata": {}, "source": ["% TODO 1: <br>\n", "Experiment with different network architectures (e.g. adjust number of units)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["% TODO 2: <br>\n", "Experiment with different mini_batch_sizes (=batch_size parameter in keras)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["% TODO 3:<br>\n", "Try to achieve the highest accuracy at the test set in the class room!"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Don't forget to store the results of the individual runs!"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.4"}}, "nbformat": 4, "nbformat_minor": 2}