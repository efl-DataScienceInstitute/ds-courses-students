{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["-------<br>\n", "Preamble and Semantic Versioning<br>\n", "-------<br>\n", "Script for a first Data Science Look in regards to the steps <br>\n", "import, pre-processing, data exploring. <br>\n", "@author: Dr. Benjamin M. Abdel-Karim<br>\n", "@since: 2023-11-03<br>\n", "@update: 2023-11-03<br>\n", "@version: 1.0.2<br>\n", "@workload 60 min"]}, {"cell_type": "markdown", "metadata": {}, "source": ["--------------<br>\n", "Imports and Setup<br>\n", "--------------<br>\n", "Import libraries for our data analysis."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import pandas as pd\n", "import matplotlib.pyplot as plt\n", "import seaborn as sns\n", "import numpy as np\n", "import os\n", "import datetime\n", "import time"]}, {"cell_type": "markdown", "metadata": {}, "source": ["# Check your working directory first.<br>\n", "Show current working directory (cwd)<br>\n", "And list all filies"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print(os.getcwd())\n", "print(os.listdir())"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Create output folder<br>\n", "Import our data set."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["now = datetime.datetime.now()\n", "date_time = now.strftime('%Y-%m-%d_%H-%M-%S')\n", "string_log_folder = 'logs/' + 'log' + '_' + date_time\n", "if not os.path.exists(string_log_folder):\n", "    os.makedirs(string_log_folder)\n", "print('// complete ....... execute folder creation: ', string_log_folder)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%%<br>\n", "--------------<br>\n", "Import the data set<br>\n", "--------------<br>\n", "Is your file in the directory? What is its name?<br>\n", "Now create a pandas dataframe."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["float_time = time.time()\n", "float_elapsed = time.time() - float_time\n", "df_raw = pd.read_csv('dataset_small.csv', sep=',')\n", "print('//complete ....... import data, run time in seconds: ', str(round(float_elapsed, 4)))"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%%<br>\n", "--------------<br>\n", "First Look<br>\n", "--------------<br>\n", "Let's have a first look at our dataset!<br>\n", "Let's see what attributes/columns we have."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print(df_raw.info())"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%% Export df_raw.info()<br>\n", "The return value from open is a file handle, <br>\n", "given out from the operating system to Python application.<br>\n", "Using @code: open, @param: w = Open a file for writing. <br>\n", "Creates a new file if it does not exist or truncates the file if it exists.<br>\n", "@param: 'w+' Open a file for updating (reading and writing).<br>\n", "@param: buf=TextIOWrapper Where to send the output. => here text object. "]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["str_output_file_name = string_log_folder + '/'+ 'df_raw_info.txt'\n", "TextIOWrapper = open(str_output_file_name, 'w+', encoding='utf-8')\n", "df_raw.info(buf=TextIOWrapper)\n", "TextIOWrapper.close()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%%<br>\n", "--------------<br>\n", "Pre-Processing: Overview<br>\n", "--------------<br>\n", "Data preprocessing is an important step in the data mining process.<br>\n", "The phrase \"garbage in, garbage out\" is particularly applicable<br>\n", "to data mining and machine learning projects.<br>\n", "So that is the number of columns. Great! Still too little information, actually.<br>\n", "I wonder what data types those specific columns are.<br>\n", "Now we're talking. We do have a lot of float values.<br>\n", "Sum all NaN Values"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["df_null_values = df_raw.isnull().sum()\n", "print(df_null_values)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%%<br>\n", "Create a plot to take another view.<br>\n", "Warning: This plot requires relatively much computing time."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["float_time = time.time()\n", "plt.figure(figsize=(15, 5))\n", "sns.heatmap(df_raw.isnull(), cbar=False, yticklabels=False, cmap='Greys')\n", "plt.xticks(rotation=45, fontsize=6)\n", "plt.tight_layout()\n", "plt.savefig(string_log_folder + '/' + 'fig_missing_values.png', dpi=300)\n", "plt.close()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["df_raw = pd.read_csv('dataset_small.csv', sep=',')\n", "print('//complete ....... ifigure: heatmap Missing Values: ', str(round( time.time() - float_time, 4)))\n", "# Note: We see columns without values. "]}, {"cell_type": "markdown", "metadata": {}, "source": ["%%<br>\n", "Drop all useless columns<br>\n", "Some attributes are droppable because they do not provide any value.<br>\n", "Let's drop these attributes. This will reduce computational complexity and<br>\n", "improve clarity of our dataset."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["df_raw = df_raw.drop(columns=['id', 'member_id', 'url', 'desc'])\n", "print(df_raw.columns)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%%<br>\n", "--------------<br>\n", "Pre-Processing: Handling Missing Values With Python Pandas (None)<br>\n", "--------------<br>\n", "NaN can be used as a numerical value on mathematical operations, <br>\n", "while None cannot (or at least shouldn't). NaN is a numeric value, <br>\n", "as defined in IEEE 754 floating-point standard. <br>\n", "None is an internal Python type (NoneType) and would be more like <br>\n", "\"inexistent\" or \"empty\" than \"numerically invalid\" in this context<br>\n", "Fill NA/NaN values using the specified method.<br>\n", "Some examples:<br>\n", "isnull() -> Checking for missing values using isnull()<br>\n", "notna() -> Indicate existing (non-missing) values"]}, {"cell_type": "markdown", "metadata": {}, "source": ["notnull() -> function gives a dataframe of Boolean values which are False for NaN values.<br>\n", "dropna() -> Drop NA/NaN row or columns wise"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Filling missing values using fillna(), replace() and interpolate()<br>\n", "fillna() -> since 2.1.0 <br>\n", "--> ffill() -> Fill values by propagating the last valid observation to next valid.<br>\n", "--> bfill() Fill values by using the next valid observation to fill the gap.<br>\n", "replace() -> Replace values given in to_replace with value.<br>\n", "interpolate()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%%<br>\n", "Our approach"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["df = df_raw.fillna(0)\n", "print('// complete ....... data pre-processing')"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%%<br>\n", "--------------<br>\n", "Data Exploring<br>\n", "--------------<br>\n", "Get all columns with numeric values."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n", "df_numbers = df.select_dtypes(include=numerics)\n", "print(df_numbers.columns)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Get all models"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["list_unique_grade = df['grade'].unique()\n", "int_unique_count_grade = len(list_unique_grade)\n", "print('// complete ........ data: unique grade: ', list_unique_grade)\n", "print('// complete ........ data: number of grades: ', int_unique_count_grade)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Super important: Slicing over column names with condition:<br>\n", "Fore more details see Pandas DataFrame operations from day 2.<br>\n", "With .iloc and loc als common approach"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["df_all_a_grades = df[df['grade'] == 'A']"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Select data where people have a high income."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["df_high_income = df[df['annual_inc'] >= 75000]"]}, {"cell_type": "markdown", "metadata": {}, "source": ["High income and high grade"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["df_high_income_and_grade = df[(df['annual_inc'] >= 75000) & (df['grade'] == 'A')]"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Get the interest rats"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["dMean_int_rate = df['int_rate'].mean()\n", "dMax_int_rate = df['int_rate'].max()\n", "dMin_int_rate = df['int_rate'].min()\n", "print('// complete ........ data int_rate min: ', dMean_int_rate)\n", "print('// complete ........ data int_rate max: ', dMax_int_rate)\n", "print('// complete ........ data int_rate min: ', dMin_int_rate)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Plot pairwise relationships in a dataset.<br>\n", "Warning: This plot requires relatively much computing time.<br>\n", "Therefore, here only a small selection of data<br>\n", "If True, don\u2019t add axes to the upper (off-diagonal)<br>\n", "triangle of the grid, making this a \u201ccorner\u201d plot."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["plt.figure()\n", "sns.pairplot(df[['loan_amnt', 'int_rate', 'installment', 'annual_inc', 'dti']], corner=True)\n", "plt.savefig(string_log_folder + '/' + 'fig_pair_plot.png', dpi=300)\n", "plt.close()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%  Label Encoding:<br>\n", "But How can we deal with other informations? <br>\n", "Do it yourself"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Check column: \"home_ownership\""]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print(df['home_ownership'].unique())"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Using Assigment based on conditions.<br>\n", "Idea based on the unique()<br>\n", "'MORTGAGE' => 1, 'RENT' => 2, 'OWN' => 3, 'ANY' => 4], defualt is 0.     <br>\n", "<br>\n", "f['home_ownership_label_endcoded'] = 0"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Execute: <br>\n", "yntax:   df.loc[df['Column'] Condition Operation 'Condition', 'new_column'] = value"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["df['home_ownership_label_endcoded'] = 0\n", "df.loc[df['home_ownership'] == 'MORTGAGE', 'home_ownership_label_endcoded'] = 1\n", "df.loc[df['home_ownership'] == 'RENT', 'home_ownership_label_endcoded'] = 2\n", "df.loc[df['home_ownership'] == 'OWN', 'home_ownership_label_endcoded'] = 3\n", "df.loc[df['home_ownership'] == 'ANY', 'home_ownership_label_endcoded'] = 4"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%% Scaling<br>\n", "Scaling Incoming and Plot the Data<br>\n", "Min Max Scaling<br>\n", "Keep it simple"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from sklearn.preprocessing import MinMaxScaler\n", "scaler = MinMaxScaler()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["df[['loan_amnt_scaled']] = scaler.fit_transform(df[['loan_amnt']]) \n", "print('// complete ....... scaling')"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["fig, ax = plt.subplots(2, sharex=False)\n", "ax[0].spines['right'].set_visible(False)\n", "ax[0].spines['top'].set_visible(False)\n", "ax[1].spines['right'].set_visible(False)\n", "ax[1].spines['top'].set_visible(False)\n", "#ax[1].yaxis.set_ticks_position('left')\n", "#ax[1].xaxis.set_ticks_position('bottom')"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["sns.histplot(data=df, x='loan_amnt', fill=False, color='black', ax=ax[0])\n", "sns.histplot(data=df, x='loan_amnt_scaled', fill=False, color='black', ax=ax[1])"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["ax[0].set_title('Loan Amnt  (Absolut)')\n", "ax[1].set_title('Loan Amnt  (Max and Min Scaled)')\n", "plt.tight_layout()\n", "sNameFigure = string_log_folder + '/' + 'fig_MinMaxScaled' + '.pdf'\n", "plt.savefig(sNameFigure)\n", "plt.close()\n", "print('// complete ....... figure')"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%%<br>\n", "--------------<br>\n", "Count Plot<br>\n", "--------------<br>\n", "Question: What is the purpose distribution of loans?<br>\n", "Why is this question relevant?<br>\n", "Show the counts of observations in each category.<br>\n", "We use bars to split our dataset by setting breakpoints.<br>\n", "In Spyder the quality could be a problem. Therefore, we use dpi param.<br>\n", "You can also save the image as pdf"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["plt.figure()\n", "ax = sns.countplot(x='purpose', data=df)\n", "plt.savefig(string_log_folder + '/' + 'fig_Purpose.png')\n", "plt.close()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Upgrade: Without borderlines"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["fig, ax = plt.subplots()\n", "ax.spines['right'].set_visible(False)\n", "ax.spines['top'].set_visible(False)\n", "ax.yaxis.set_ticks_position('left')\n", "ax.xaxis.set_ticks_position('bottom')\n", "ax = sns.countplot(x='purpose', data=df, palette='Greys')\n", "plt.xticks(rotation=45, fontsize=6)\n", "plt.xlabel('Purpose')\n", "plt.ylabel('Count')\n", "plt.title('Purpose of Use')\n", "plt.tight_layout()\n", "plt.savefig(string_log_folder + '/' + 'fig_PurposeImprove_300.png', dpi=300)\n", "plt.close()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%%<br>\n", "--------------<br>\n", "Boxplot<br>\n", "--------------<br>\n", "Question:<br>\n", "What is the interest rate per class?"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["plt.figure()\n", "sns.boxplot(x='grade', y='loan_amnt', data=df, showfliers=False, palette='Greys')\n", "plt.xticks(rotation=45, fontsize=6)\n", "plt.title('Loan Amount by Class')\n", "plt.savefig(string_log_folder + '/' + 'fig_GradesLoanAmountImprove.png')\n", "plt.close()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%%<br>\n", "--------------<br>\n", "plot.bar<br>\n", "--------------<br>\n", "Selected all loan status."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print(df['loan_status'].unique())"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["LBad_indicators = ['Charged Off',\n", "                    'Default',\n", "                    'Does not meet the credit policy. Status:Charged Off',\n", "                    'In Grace Period',\n", "                    'Default Receiver',\n", "                    'Late (16-30 days)',\n", "                    'Late (31-120 days)']"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Define a bad loan in our DataFrame.<br>\n", "Add all bad loans in our DataFrame."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["df['bad_loan'] = 0\n", "df.loc[df.loan_status.isin(LBad_indicators), 'bad_loan'] = 1"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Using croup by"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["dict_risk = df.groupby(['grade'])['bad_loan'].mean().sort_values().to_dict()\n", "print(dict_risk)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["plt.figure()\n", "df.groupby(['grade'])['bad_loan'].mean().sort_values().plot.bar()\n", "plt.ylabel('Percentage of Bad Debt')\n", "plt.savefig(string_log_folder + '/' + 'fig_RiskProfile.png')\n", "plt.close()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%%<br>\n", "--------------<br>\n", "Boxplot<br>\n", "--------------<br>\n", "Question: Loan interest by class<br>\n", "Why is this question relevant?"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["plt.figure()\n", "sns.boxplot(x='grade', y='int_rate', data=df)\n", "plt.savefig(string_log_folder + '/' + 'fig_GradesIntRate.png')\n", "# plt.show()\n", "plt.close()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["# Final plot."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["plt.figure()\n", "sns.boxplot(x='grade', y='int_rate', data=df,\n", "             showfliers=False, palette='Blues',\n", "             order=['A', 'B', 'C', 'D', 'E', 'F', 'G'])\n", "plt.xticks(rotation=45, fontsize=6)\n", "plt.title('Interest Rat and Grade in Order')\n", "plt.savefig(string_log_folder + '/' + 'fig_GradesIntRateOrder.png')\n", "# plt.show()\n", "plt.close()\n", "print('// complete ....... data exploring part I')"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%%<br>\n", "--------------<br>\n", "Heatmap<br>\n", "--------------<br>\n", "Create a Heatmap for corr()<br>\n", " # or df.loc[:, ['C', 'D', 'E']<br>\n", "Rember data:<br>\n", "loanAmnt = The listed amount of the loan applied for by the borrower.<br>\n", "If at some point in time, the credit department<br>\n", "reduces the loan amount, then it will be reflected in this value."]}, {"cell_type": "markdown", "metadata": {}, "source": ["installment = The monthly payment<br>\n", "owned by the borrower if the loan originates."]}, {"cell_type": "markdown", "metadata": {}, "source": ["annualInc = The self-reported annual income provided<br>\n", "by the borrower during registration."]}, {"cell_type": "markdown", "metadata": {}, "source": ["dti = A ratio calculated using the borrower\u2019s total monthly<br>\n", "debt payments on the total debt obligations,<br>\n", "excluding mortgage and the requested LC loan,<br>\n", "divided by the borrower\u2019s self-reported monthly income."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["df_ForCorr = df[['loan_amnt', 'int_rate', 'installment', 'annual_inc', 'dti']]\n", "corr = df_ForCorr.corr()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Create Corr figure with headmap."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["plt.figure()\n", "sns.heatmap(corr,\n", "        xticklabels=corr.columns,\n", "        yticklabels=corr.columns, annot=True)\n", "plt.tight_layout()\n", "plt.savefig(string_log_folder + '/' + 'fig_CoreHeatmap.pdf')\n", "# plt.show()\n", "plt.close()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%%<br>\n", "Update the corr plot with mask.<br>\n", "Generate a mask for the upper triangle.<br>\n", "@source: https://seaborn.pydata.org/examples/many_pairwise_correlations.html<br>\n", "@code: np.zeros_like() return an array of zeros with the same shape and type as a given array.<br>\n", "@code: np.triu_indices_from() return the indices for the upper-triangle of arr."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["plt.figure()\n", "mask = np.zeros_like(corr, dtype=bool)\n", "mask[np.triu_indices_from(mask)] = True\n", "sns.heatmap(corr,\n", "        xticklabels=corr.columns,\n", "        yticklabels=corr.columns, annot=True, mask=mask)\n", "plt.tight_layout()\n", "plt.savefig(string_log_folder + '/' + 'fig_CoreHeatmapUpdate.pdf')\n", "plt.close()\n", "print('// complete ....... data exploring part II')"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%%<br>\n", "--------------<br>\n", "cloroplot<br>\n", "--------------<br>\n", "More plots here<br>\n", "We define a function for plotting the data on a cloropleth plot. A cloropleth<br>\n", "plot allows us to plot data on an (interactive) map. Why should we use a function?<br>\n", "Because we will use it multiple times, so we make our code cleaner.<br>\n", "Type in your terminal: pip3 install plotly"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["state_mean = pd.DataFrame(df.groupby('addr_state')['loan_amnt'].mean())\n", "from plotly.offline import plot\n", "import plotly.graph_objects as go"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def cloroplot(data, z, title):\n", "    fig = go.Figure(data=go.Choropleth(\n", "        locations=data.index,  # Spatial coordinates\n", "        z=data[z].astype(float),  # Data to be color-coded\n", "        locationmode='USA-states',  # set of locations match entries in `locations`\n", "        colorscale='Reds',\n", "        colorbar_title=\"in USD\",\n", "    ))\n", "    fig.update_layout(\n", "        title_text=title,\n", "        geo_scope='usa',  # limite map scope to USA\n", "    )\n", "    plot(fig)\n", "cloroplot(state_mean, 'loan_amnt', 'Mean loans by State')\n", "print('// complete ....... data exploring part III')"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.4"}}, "nbformat": 4, "nbformat_minor": 2}