{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e0c5c23",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Remember: Either assign the results of your code statements to a variable \n",
    "or print them out on the console by wrapping your code statement with \"print()\".\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0cf3074",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries for our data analysis.\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy  as np\n",
    "import csv\n",
    "\n",
    "\n",
    "######################################\n",
    "### Data Import and Pandas Intro  ####\n",
    "######################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f117e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import our data set.\n",
    "# Check your working directory first.\n",
    "print(\"Current working directory:\", os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3676ae6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Is your file in the directory? What is its name?\n",
    "print(\"Files located in the directory:\", os.listdir())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fa08bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change your working directory to where the file is, if the file is not in the current directory\n",
    "os.chdir(r\"...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d4905f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the file via csv commands. Print the first ten rows. \n",
    "# You can achieve this by converting the csv.reader into a list and then\n",
    "# iterating on it.\n",
    "with open(\"...\", \"r\") as file: \n",
    "    reader = csv.reader(file, delimiter=\",\")  \n",
    "    rows = list(reader)\n",
    "    for i in range(...):\n",
    "        print(rows[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "042fde59",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "# Now we could do some simple operations on the file.\n",
    "# Since we want to do a lot of data exploration and analysis, this would only\n",
    "# result in burdensome work and unreadable code. \n",
    "# Therefore, this does not help us much.\n",
    "        \n",
    "# Another option would be to load the data into a dictionary or list with\n",
    "# sub- datastructures. This would also get very burdensome and computationally\n",
    "# inefficient.\n",
    "    \n",
    "# Thankfully, there is pandas. Pandas allows us to load files of various\n",
    "# file types into a data structure called DataFrame.\n",
    "# This gives us a persistent datastructure to work with and perform our \n",
    "# analyses on. \n",
    "# DataFrames represent data in a tabular way, much like excel sheets.\n",
    "# DataFrames therefore consist of rows and columns. Columns are called \n",
    "# 'Series' and are a subordinate data structure - that holds a column of data.\n",
    "# Rows contain the actual data.\n",
    "\n",
    "# Fantastic! Let's read our csv into a pandas DataFrame.\n",
    "\n",
    "# Now create a pandas dataframe.\n",
    "df = ...\n",
    "\n",
    "# Great. Pandas is a very useful package for data analysis. Similar to other\n",
    "# packages, it does not only come with the very useful DataFrame data structure,\n",
    "# but also a lot of functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19379fa8",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "# Let's see how many functions pandas actually provides.\n",
    "\n",
    "print(...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0275404",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrame functions provide direct and matched operations for DataFrame types.\n",
    "# List the functions to get an overview.\n",
    "\n",
    "print(...)\n",
    "\n",
    "# Quite overwhelming how powerful pandas appears to be! In the following section,\n",
    "# we will look at some of these useful functions and features of pandas\n",
    "# for data analysis purposes. \n",
    "\n",
    "# The functions we are going to go through will empower you to:\n",
    "#   - Get an overview over the dataset\n",
    "#   - Get descriptive statistics on the dataset\n",
    "#   - Find first indices for correlations in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a126f36",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "#########################\n",
    "### Data Exploration ####\n",
    "#########################\n",
    "\n",
    "# exploring dataset\n",
    "\n",
    "#info, datatypes in df\n",
    "\n",
    "# At first, we have to get a grip of the dataset. Let's print the columns.\n",
    "\n",
    "print(df...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c71ed5f3",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "# That's quite some columns. How many, actually?\n",
    "\n",
    "print(...(df...))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ae6b4fb",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "# We can also return a tuple representing the dimensionality of the DataFrame,\n",
    "# to see how many records and columns we have.\n",
    "print('Dimensionality of the DataFrame')\n",
    "df_shape = ...\n",
    "print(...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4278ffa9",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "# So that is the number of columns. Great! Still too little information actually.\n",
    "# Let's find out, what datatypes those specific columns are.\n",
    "\n",
    "print('info')\n",
    "df_info = df....\n",
    "print(...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f915b603",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "# In your very first python session, you learned about primitive datatypes,\n",
    "# such as int, string, float. Complex datatypes are almost always represented\n",
    "# as objects. Let's print the column 'Name' with the object datatype, to see\n",
    "# if it is really complex and why it is labeled as object.\n",
    "\n",
    "# Try to print the 'Name' column. Attention! There are two obvious ways\n",
    "# to do this.\n",
    "\n",
    "print(df...)\n",
    "print(df...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "035a4d60",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "# As we can see, the object datatype actually contains strings. Pandas\n",
    "# initially tries to assign datatypes to the various columns, but sometimes it\n",
    "# does not get the correct type. Why is that so?\n",
    "# (See: https://pandas.pydata.org/pandas-docs/stable/getting_started/basics.html#dtypes)\n",
    "# Citation: Pandas uses the object dtype for storing strings.\n",
    "\n",
    "# Problem solved. But what about Year? Should it not be int? Print the column.\n",
    "\n",
    "print(df...)\n",
    "print(df...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a274063d",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "# It should be int, yet it has been assigned float values.\n",
    "# Again, we find our answer in the pandas documentation\n",
    "# See: https://pandas.pydata.org/docs/user_guide/integer_na.html\n",
    "\n",
    "# Citation: Because NaN is a float, a column of integers with even \n",
    "#           one missing values is cast to floating-point dtype \n",
    "#           (see Support for integer NA for more).\n",
    "\n",
    "# This explains the issue. Let's check for missing values if it is true for\n",
    "# the dataset.\n",
    "\n",
    "print('There are missing values')\n",
    "df_null_values = df....\n",
    "print(...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac4451b6",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "# Indeed! We have 271 missing values in the Year column, as well as some in the\n",
    "# publisher column. \n",
    "# We could now decide to drop all the rows, where information\n",
    "# is missing, try to fill it with sample data (not very useful in our case)\n",
    "# or drop the column (also not useful).\n",
    "\n",
    "# Since we have a lot of data, we will drop the rows where year and publisher\n",
    "# data is missing. Use pd.DataFrame.dropna on our dataframe to drop the\n",
    "# rows. Then print the info on our dataset again.\n",
    "\n",
    "df = df....(axis=0)\n",
    "df...()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1436a490",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The 306 records have been dropped, such that we now only have 16291 records.\n",
    "# It appears that Year is still a float. Let's convert it to int.\n",
    "# See: https://pandas.pydata.org/pandas-docs/stable/getting_started/basics.html#astype\n",
    "# Then print info again.\n",
    "df['Year'] = df['Year']....('int64') \n",
    "df.info()\n",
    "\n",
    "# Great job! You have successfully cleaned your data from rows with missing\n",
    "# values and converted a column to its correct datatype."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97219ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternatively, we can load the dataset with dtype_backend=´numpy_nullable´ to\n",
    "# get the right datatype\n",
    "df_alternative = ...\n",
    "\n",
    "# In this case, we still need to drop the missing values\n",
    "df_alternative = df....(axis=0)\n",
    "df_alternative....()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7f1478e",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "# Let's start with some manipulation and analysis.\n",
    "\n",
    "# Let's see what the top rows and the bottom rows look like.\n",
    "\n",
    "\n",
    "df....()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e66f44f",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "df....()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22c90b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get access to the 55 record. There are two options.\n",
    "\n",
    "df...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf1322c",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "df...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a5f8220",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "# While loc searches the index by named labels (such as strings, but also int),\n",
    "# iloc searches for row number.\n",
    "# The differentiation of these two will become much clearer when performing\n",
    "# slicing operations. Remember the slicing operations for strings and lists.\n",
    "# In our case, the first part of the slice before the comma refers to the\n",
    "# records (x-axis), the second to the columns (y-axis).\n",
    "\n",
    "# Let’s perform a slice on the rows until index 3, and columns until index 3.\n",
    "\n",
    "df_slice_1 = df...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df9f86d5",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "# This gives us a 3x3 snapshot of the dataframe, starting at the  \n",
    "# column 0 ( index) and stopping at the column 4 (with index 3)\n",
    "# does it work the same way with loc? Print the result.\n",
    "df.... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "769c6fc1",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "# Nope. we learned that loc works with 'named' labels. Since the rows have\n",
    "# numeric labels, we can change the first part according to the number of instances\n",
    "# that we want to keep. Be careful, loc includes the last element of the slice. \n",
    "# Let's change the second part to the column label. Print the result.\n",
    "\n",
    "df.... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "871f77f8",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "# Another example: find the last element with the ID 16597 with loc and iloc\n",
    "# Print the result.\n",
    "df...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "163557a3",
   "metadata": {
    "lines_to_next_cell": 0,
    "title": "Print the result."
   },
   "outputs": [],
   "source": [
    "df....\n",
    "\n",
    "# different story: know that iloc works with indices. We do have a first column\n",
    "# that is named index, yet is not consistent with our actual dataset index.\n",
    "# This is sometimes native to the dataset, sometimes caused by record drops."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77cb340d",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "# remember, we dropped a few NA rows. To showcase this\n",
    "# use loc to get the element with index 180 \n",
    "df...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "326595b6",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "# now try it with iloc\n",
    "df...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d3f039b",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "# we get a different record. Why? Due to dropping of na values, the position of\n",
    "# record with index 180 is shifted. \n",
    "df...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d64746",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "# We can clean up the index with this function.\n",
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c62887d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 16597 would have been the last element. Let's try to get it another way.\n",
    "df.iloc[...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d130b33",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "# Let's to some advanced stuff now!\n",
    "# You have learned about basic data structures.\n",
    "# Retain the a subset of the DataFrame containing the records 10-20 (including 10 and 20)\n",
    "#and columns Platform - NA_Sales.\n",
    "\n",
    "# do it with iloc.\n",
    "df.iloc[...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59e556f7",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "# do it with loc.\n",
    "df.loc[...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b77951b3",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "# write the contents of the last operation to a dict. \n",
    "# There is a helpful function for writing a df to a dict, the to_dict() function \n",
    "df_slice = df.loc[...]\n",
    "Dslice = df_slice...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88cbdd0c",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "# Hmm... this does not look quite right. We want the rows to be the keys,\n",
    "# not the columns. Let's see what a df.transpose can do.\n",
    "df_slice_transposed = df_slice....\n",
    "Dslice_transposed = df_slice_transposed...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4501ff3",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "# Perfect, this is what we wanted. What actually just happened?\n",
    "# By transposing the dataframe, we changed the columns to rows and the rows to\n",
    "# columns. This can sometimes be very helpful in data analysis, for example\n",
    "# if you need to convert the data structure or the size of the data structure.\n",
    "# Especially in Machine Learning and Deep Learning with Neural Nets,\n",
    "# being able to transpose data structures is an invaluable feature (pun intended)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b76bbdb2",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "\n",
    "######################################################\n",
    "##  Descriptive Statistics with Pandas ##\n",
    "######################################################\n",
    "\n",
    "\n",
    "# Numpy has a multitude of different functions that are useful as well.\n",
    "# Many of these functions are also inherited by the pandas packages\n",
    "# and the pandas Dataframe, such as several functions for \n",
    "# descriptive statistics.\n",
    "\n",
    "# descriptive stats\n",
    "# Try to find these functions within the pandas package and perform them on\n",
    "# our dataframe!\n",
    "\n",
    "df_mean = df....(...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc336f8b",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "df_max = df....(...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bdb5eb3",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "df_min = df....(...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf8a75c3",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "df_q3 = df....(...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7787f2a7",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "df_qmed = df....(...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b28f5a71",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "df_q1 = df....(...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "496e0782",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "df_std = df....(...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4edff946",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "df_count = df...()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a60ee3e6",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "# There are also important aggregate functions that deliver the most\n",
    "# interesting desc. stats at once.\n",
    "\n",
    "df_description = df....()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "013f9d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To find first hints on how features (another name for our attributes or\n",
    "# columns that is used in data analysis) correlate, use the correlation\n",
    "# function.\n",
    "\n",
    "df_corr = df....(...)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "title,-all",
   "encoding": "# -*- coding: utf-8 -*-",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
